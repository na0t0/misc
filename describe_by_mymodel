class Config:
    learning_rate = 0.0005
    weight_decay = 0.01
    adam_epsilon = 1e-8
    warmup_steps = 2
    batch_size = 2
    num_worker = 2
    num_train_epochs = 10
    gradient_accumulation_steps = 1
    sample_rate = 48000
class WhisperModelModule(LightningModule):
  <ここに関しては割愛>

cfg = Config()
checkpoint_path = "/home/whisper/content/aaa.ckpt"
state_dict = torch.load(checkpoint_path)
state_dict = state_dict['state_dict']
whisper_model = WhisperModelModule(cfg)
whisper_model.eval()
whisper_model.freeze()
whisper_model.load_state_dict(state_dict)
wavdata= whisper.load_audio(f"/home/whisper/aaa.wav")
result = whisper_model.model.transcribe(wavdata, verbose=True, temperature=0.8, language="ja")
#print(result["text"])
